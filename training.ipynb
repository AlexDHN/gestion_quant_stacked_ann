{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from classes.Ann import Ann\n",
    "from classes.DataLoader import DataLoader\n",
    "from classes.DataLoader_batch import DataLoader_batch\n",
    "from classes.Simulation import Simulation\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.init_functions import random_normal\n",
    "from arch import arch_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = \"S&P500\"\n",
    "data = pd.read_csv(\"data/dataset.csv\", index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "df_trv = data.rolling(5).std()\n",
    "df_trv.index = pd.to_datetime(df_trv.index)\n",
    "df_trv = df_trv.iloc[4:]\n",
    "dfe = df_trv[index].dropna() \n",
    "mi = dfe.min()\n",
    "ma = dfe.max()\n",
    "dfe = (dfe - mi)/(ma-mi)\n",
    "dfe_r = data[\"S&P500\"][dfe.index]\n",
    "\n",
    "am = arch_model(dfe_r.values, p=1, q=1)\n",
    "res = am.fit(disp='off')\n",
    "dfe_garch = pd.Series(res.conditional_volatility, index=dfe_r.index)\n",
    "mi_garch = dfe_garch.min()\n",
    "ma_garch = dfe_garch.max()\n",
    "dfe_garch = (dfe_garch - mi_garch)/(ma_garch-mi_garch)\n",
    "\n",
    "am = arch_model(dfe_r.values, vol='EGARCH' , p = 1 , o = 0 , q = 1)\n",
    "res = am.fit(disp='off')\n",
    "dfe_egarch = pd.Series(res.conditional_volatility, index=dfe_r.index)\n",
    "mi_egarch = dfe_egarch.min()\n",
    "ma_egarch = dfe_egarch.max()\n",
    "df_egarch = (dfe_egarch - mi_egarch)/(ma_egarch-mi_egarch)\n",
    "\n",
    "periods = {\n",
    "    \"2000-2007\":\"2008\",\n",
    "    \"2001-2008\":\"2009\",\n",
    "    \"2002-2009\":\"2010\",\n",
    "    \"2009-2016\":\"2017\",\n",
    "    \"2010-2017\":\"2018\",\n",
    "}\n",
    "\n",
    "params_stacked = {\n",
    "    \"2000-2007\":[0.0033,0],\n",
    "    \"2001-2008\":[0.0059, 0.01],\n",
    "    \"2002-2009\":[0.0136, 0],\n",
    "    \"2009-2016\":[0.085, 0.02],\n",
    "    \"2010-2017\":[0.01, 0.011],\n",
    "}\n",
    "\n",
    "params_ml = {\n",
    "    \"2000-2007\":[10, 24, 1479, 0.003, 0.0001, 0.45],\n",
    "    \"2001-2008\":[10, 107, 3000, 0.001, 0.0001, 0.55],\n",
    "    \"2002-2009\":[1, 37, 3583, 0.001, 0.0004, 0.17],\n",
    "    \"2009-2016\":[30, 118, 1000, 0.009, 0.0002, 0.13],\n",
    "    \"2010-2017\":[7, 175, 1000, 0.003, 0.0001, 0.54],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0366 | Test loss: 0.0746: 100%|██████████| 10000/10000 [01:22<00:00, 121.55it/s]\n",
      "Train loss: 0.0256 | Test loss: 0.5177: 100%|██████████| 10000/10000 [01:14<00:00, 133.68it/s]\n",
      "Train loss: 0.0307 | Test loss: 1.9208: 100%|██████████| 10000/10000 [01:16<00:00, 131.40it/s]\n",
      "Train loss: 0.0176 | Test loss: 0.1917: 100%|██████████| 10000/10000 [01:16<00:00, 130.85it/s]\n",
      "Train loss: 0.0340 | Test loss: 0.0425: 100%|██████████| 10000/10000 [01:18<00:00, 127.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for period in periods:\n",
    "\n",
    "    df = dfe[period[:4]:period[5:]]\n",
    "\n",
    "    pivot_index_training_1 = round(df.shape[0] * 0.25)\n",
    "    pivot_index_training_2 = round(df.shape[0] * 0.75)\n",
    "\n",
    "    df_train_1 = df.iloc[:pivot_index_training_1]\n",
    "    df_ann = df.iloc[pivot_index_training_1:]\n",
    "\n",
    "    ite_train_1 = DataLoader(df=df_train_1, Y=df_train_1.values, window_size=30, batch_size=df_train_1.shape[0])\n",
    "    for batch in ite_train_1: # Only one batch there\n",
    "        X_train_1,y_train_1 = batch\n",
    "\n",
    "    rf_rgs = RandomForestRegressor(n_estimators=params_ml[period][0], max_depth=params_ml[period][1])  # RandomForestRegressor(max_features = 10, min_samples_split = 24)   \n",
    "    rf_rgs.fit(X_train_1,y_train_1)\n",
    "\n",
    "    sv_rgs = SVR(kernel='rbf', gamma=params_ml[period][4], epsilon=params_ml[period][5])\n",
    "    sv_rgs.fit(X_train_1,y_train_1)\n",
    "\n",
    "    gb_rgs = GradientBoostingRegressor(learning_rate=params_ml[period][3], n_estimators=params_ml[period][2])  # GradientBoostingRegressor(learning_rate = 0.003, n_estimators=1479)\n",
    "    gb_rgs.fit(X_train_1,y_train_1)\n",
    "\n",
    "    ite = DataLoader(df=df_ann, Y=df_ann.values, window_size=30, batch_size=df_ann.shape[0])\n",
    "    for batch in ite: # Only one batch there\n",
    "        X,y = batch\n",
    "\n",
    "    df_train_ann = pd.DataFrame(X, index=df_ann.index[30:])\n",
    "    df_train_ann[\"rf\"] = rf_rgs.predict(X)\n",
    "    df_train_ann[\"sv\"] = sv_rgs.predict(X)\n",
    "    df_train_ann[\"gb\"] = gb_rgs.predict(X)\n",
    "\n",
    "    kwargs = dict(\n",
    "        learning_rate = params_stacked[period][0],\n",
    "        period = period,\n",
    "        batch_size = df_train_ann.shape[0],\n",
    "        num_epochs = 10000, \n",
    "        window_size = 30,\n",
    "        weight_decay = 0,\n",
    "        tab = df_train_ann.values,\n",
    "        #l2_lambda = params_stacked[period][1],\n",
    "        y = y,\n",
    "    )\n",
    "\n",
    "    sim = Simulation(**kwargs)\n",
    "    sim.Ann.init_weights(random_normal)\n",
    "    sim.make_dataloaders(pivot_index=pivot_index_training_2-pivot_index_training_1)\n",
    "    sim.train(verbose=1)\n",
    "    sim.Ann.save(\"models/torch/stacked_ann/{}\".format(period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward-Ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0380 | Test loss: 0.0613: 100%|██████████| 10000/10000 [01:10<00:00, 142.01it/s]\n",
      "Train loss: 0.0249 | Test loss: 0.4544: 100%|██████████| 10000/10000 [01:15<00:00, 132.71it/s]\n",
      "Train loss: 0.0266 | Test loss: 3.7517: 100%|██████████| 10000/10000 [01:15<00:00, 131.89it/s]\n",
      "Train loss: 0.0171 | Test loss: 0.2022: 100%|██████████| 10000/10000 [01:17<00:00, 129.76it/s]\n",
      "Train loss: 0.0394 | Test loss: 0.0402: 100%|██████████| 10000/10000 [01:12<00:00, 137.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for period in periods:\n",
    "\n",
    "    df = dfe[period[:4]:period[5:]]\n",
    "\n",
    "    pivot_index_training_1 = round(df.shape[0] * 0.25)\n",
    "    pivot_index_training_2 = round(df.shape[0] * 0.75)\n",
    "\n",
    "    df_ann = df.iloc[pivot_index_training_1:]\n",
    "\n",
    "    ite = DataLoader(df=df_ann, Y=df_ann.values, window_size=30, batch_size=df_ann.shape[0])\n",
    "    for batch in ite: # Only one batch there\n",
    "        X,y = batch\n",
    "\n",
    "    kwargs = dict(\n",
    "        learning_rate = params_stacked[period][0],\n",
    "        period = period,\n",
    "        batch_size = len(X),\n",
    "        num_epochs = 10000, \n",
    "        window_size = 30,\n",
    "        weight_decay = 0,\n",
    "        #l2_lambda = params_stacked[period][1],\n",
    "        tab = X,\n",
    "        y = y,\n",
    "    )\n",
    "\n",
    "    sim = Simulation(**kwargs)\n",
    "    sim.Ann.init_weights(random_normal)\n",
    "    sim.make_dataloaders(pivot_index=pivot_index_training_2-pivot_index_training_1)\n",
    "    sim.train(verbose=1)\n",
    "    sim.Ann.save(\"models/torch/feed_forward_ann/{}\".format(period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ann-Garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0543 | Test loss: 0.0734: 100%|██████████| 10000/10000 [01:05<00:00, 151.82it/s]\n",
      "Train loss: 0.0334 | Test loss: 0.8235: 100%|██████████| 10000/10000 [01:10<00:00, 142.31it/s]\n",
      "Train loss: 0.0331 | Test loss: 3.9470: 100%|██████████| 10000/10000 [01:13<00:00, 135.26it/s]\n",
      "Train loss: 0.0223 | Test loss: 0.2113: 100%|██████████| 10000/10000 [01:13<00:00, 135.44it/s]\n",
      "Train loss: 0.0623 | Test loss: 0.0556: 100%|██████████| 10000/10000 [01:16<00:00, 131.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for period in periods:\n",
    "\n",
    "    df = dfe[period[:4]:period[5:]]\n",
    "    df_garch = dfe_garch[period[:4]:period[5:]]\n",
    "\n",
    "    pivot_index_training_1 = round(df.shape[0] * 0.25)\n",
    "    pivot_index_training_2 = round(df.shape[0] * 0.75)\n",
    "\n",
    "    df_ann = df.iloc[pivot_index_training_1:]\n",
    "    df_ann_garch = df_garch.iloc[pivot_index_training_1:]\n",
    "\n",
    "    ite = DataLoader(df=df_ann, Y=df_ann.values, window_size=30, batch_size=df_ann.shape[0])\n",
    "    for batch in ite: # Only one batch there\n",
    "        X,y = batch\n",
    "\n",
    "    ite_garch = DataLoader(df=df_ann_garch, Y=df_ann_garch.values, window_size=30, batch_size=df_ann_garch.shape[0])\n",
    "    for batch in ite_garch: # Only one batch there\n",
    "        X_garch,y_garch = batch\n",
    "\n",
    "    kwargs = dict(\n",
    "        learning_rate = params_stacked[period][0],\n",
    "        period = period,\n",
    "        batch_size = len(X_garch),\n",
    "        num_epochs = 10000, \n",
    "        window_size = 30,\n",
    "        weight_decay = 0,\n",
    "        #l2_lambda = params_stacked[period][1],\n",
    "        tab = X_garch,\n",
    "        y = y,\n",
    "    )\n",
    "\n",
    "    sim = Simulation(**kwargs)\n",
    "    sim.Ann.init_weights(random_normal)\n",
    "    sim.make_dataloaders(pivot_index=pivot_index_training_2-pivot_index_training_1)\n",
    "    sim.train(verbose=1)\n",
    "    sim.Ann.save(\"models/torch/ann_garch/{}\".format(period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ann-egarch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0636 | Test loss: 0.0653: 100%|██████████| 10000/10000 [01:08<00:00, 146.49it/s]\n",
      "Train loss: 0.0398 | Test loss: 0.4191: 100%|██████████| 10000/10000 [01:39<00:00, 100.24it/s]\n",
      "Train loss: 0.0554 | Test loss: 0.5598: 100%|██████████| 10000/10000 [01:21<00:00, 123.01it/s]\n",
      "Train loss: 0.0760 | Test loss: 0.1084: 100%|██████████| 10000/10000 [01:19<00:00, 125.63it/s]\n",
      "Train loss: 0.0665 | Test loss: 0.0538: 100%|██████████| 10000/10000 [01:17<00:00, 128.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for period in periods:\n",
    "\n",
    "    df = dfe[period[:4]:period[5:]]\n",
    "    df_egarch = dfe_egarch[period[:4]:period[5:]]\n",
    "\n",
    "    pivot_index_training_1 = round(df.shape[0] * 0.25)\n",
    "    pivot_index_training_2 = round(df.shape[0] * 0.75)\n",
    "\n",
    "    df_ann = df.iloc[pivot_index_training_1:]\n",
    "    df_ann_egarch = df_egarch.iloc[pivot_index_training_1:]\n",
    "\n",
    "    ite = DataLoader(df=df_ann, Y=df_ann.values, window_size=30, batch_size=df_ann.shape[0])\n",
    "    for batch in ite: # Only one batch there\n",
    "        X,y = batch\n",
    "\n",
    "    ite_garch = DataLoader(df=df_ann_egarch, Y=df_ann_egarch.values, window_size=30, batch_size=df_ann_egarch.shape[0])\n",
    "    for batch in ite_garch: # Only one batch there\n",
    "        X_egarch,y_egarch = batch\n",
    "\n",
    "    kwargs = dict(\n",
    "        learning_rate = params_stacked[period][0],\n",
    "        period = period,\n",
    "        batch_size = len(X_egarch),\n",
    "        num_epochs = 10000, \n",
    "        window_size = 30,\n",
    "        weight_decay = 0,\n",
    "        #l2_lambda = params_stacked[period][1],\n",
    "        tab = X_egarch,\n",
    "        y = y,\n",
    "    )\n",
    "\n",
    "    sim = Simulation(**kwargs)\n",
    "    sim.Ann.init_weights(random_normal)\n",
    "    sim.make_dataloaders(pivot_index=pivot_index_training_2-pivot_index_training_1)\n",
    "    sim.train(verbose=1)\n",
    "    sim.Ann.save(\"models/torch/ann_egarch/{}\".format(period))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9b04fdcb430474004bc74d2d28d415b40d0bb88a523fdc7d942e25fe1aa22b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
